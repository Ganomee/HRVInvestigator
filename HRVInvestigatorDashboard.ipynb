{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7f16518-1932-439d-85da-a84d16778ee8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# HRV Investigator - Overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95c01707-dd19-4085-be4b-9c5f96c45fa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports / Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e40a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import param\n",
    "import ipywidgets as ipywidget\n",
    "import pickle\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource\n",
    "import os\n",
    "\n",
    "# def checkAndInstallPip(package_name):\n",
    "#     if importlib.util.find_spec(package_name) is not None:\n",
    "#         print(f\"{package_name!r} already installed\")\n",
    "#     else:        \n",
    "#         print(f\"{package_name!r} will be installed\")\n",
    "#         !{sys.executable} - m pip install {package_name}\n",
    "\n",
    "\n",
    "# def checkAndInstallConda(package_name, channel=None):\n",
    "#     if importlib.util.find_spec(package_name) is not None:\n",
    "#         print(f\"{package_name!r} already installed\")\n",
    "#     else:\n",
    "#         print(f\"{package_name!r} will be installed\")\n",
    "#         if channel is not None:\n",
    "#             %conda install - -yes - -prefix {sys.prefix} - c {channel} {package_name}\n",
    "#         else:\n",
    "#             %conda install - -yes - -prefix {sys.prefix} {package_name}\n",
    "\n",
    "# try:\n",
    "#     checkAndInstallConda(\"ipywidgets\", sys.prefix)\n",
    "# except ImportError as e:\n",
    "#     print(\"error\", e)\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     checkAndInstallPip(\"numpy\")\n",
    "#     checkAndInstallPip(\"mne\")\n",
    "#     checkAndInstallPip(\"bqplot\")\n",
    "#     checkAndInstallPip(\"holoviews\")\n",
    "# except ImportError as e:\n",
    "#     print(\"error\", e)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c91442-78d6-4ef9-987f-16b4adc1771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel Initialisation\n",
    "#pn.extension( css_files=[\"./style/dist/hrv.css\"])\n",
    "\n",
    "pn.extension('terminal', 'gridstack')\n",
    "pn.config.comms = \"vscode\"\n",
    "pn.param.ParamMethod.loading_indicator = True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "603e0c66-c8ad-4dc2-a532-73fdd02d655f",
   "metadata": {},
   "source": [
    "# Data Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import param\n",
    "from components.dataStructure import DataHistoryItem, DataHistoryList\n",
    "from components.common.activeECGDataSelector import ECGHistorySelector, ECGRunSelector\n",
    "\n",
    "# Layout panes\n",
    "# Subcompoents of these panels are defined in their respective section\n",
    "processing_panel = None\n",
    "insights_panel = None\n",
    "\n",
    "ml_panel = None\n",
    "data_panel = None  # For managing storing and loading data\n",
    "console_panel = None  # For displaying messages and errors\n",
    "dashboard = None\n",
    "\n",
    "# Main DataFrame\n",
    "main_ecg_history = DataHistoryList()  \n",
    "\n",
    "# pathDefinition\n",
    "absPath = os.path.abspath('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e58d18c1-3254-45b0-a9e2-cb0cf3dbc181",
   "metadata": {},
   "source": [
    "# Temp - DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "\n",
    "def loadData():\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    import os\n",
    "    absPath=\"\"\n",
    "    \n",
    "    fileName = \"/Users/shivam/Documents/GitHub/HRVInvestigator/DataArtifacts/demo_data.pickle\"\n",
    "    # combine to total path \n",
    "    filePath = os.path.join(absPath, fileName)\n",
    "    \n",
    "    file = h5py.File('/Users/shivam/Documents/GitHub/HRVInvestigator/DataArtifacts/ecg.mat', 'r')\n",
    "\n",
    "    # Access the ECG data\n",
    "    ecg_data = file['ecg'][:].flatten()\n",
    "    \n",
    "    \n",
    "    data_obj = main_ecg_history.addNewFromDict({\"data\": ecg_data, \"features\": {\"sfreq\": file[\"header\"][\"sampling_rate\"][0]}, \"name\": \"ECG\", \"mlRuns\": {}})\n",
    "    file.close()\n",
    "    # print(\"HERE\")\n",
    "    # with open(filePath, \"wb\") as f:\n",
    "    #         pickle.dump(data_obj.getSaveDict(), f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def loadfeature30data():\n",
    "    filepath = \"/Users/shivam/Documents/GitHub/HRVInvestigator/DataArtifacts/features_30.pkl\"\n",
    "    obj = pd.read_pickle(filepath)\n",
    "    # obj.plot(subplots=True, kind = \"kde\")\n",
    "    fig = sp.make_subplots(rows=int(obj.shape[1]/3), cols=3)\n",
    "    i=0\n",
    "    j=0\n",
    "    for col in obj.columns:\n",
    "        hist1 = px.histogram(obj[col], x=col, histnorm='density', nbins=1000)\n",
    "        fig.add_trace(hist1.data[0], row=i+1, col=j+1)\n",
    "        fig.update_xaxes(title_text=col, row=i+1, col=j+1)\n",
    "        # subobj.plot(kind=\"kde\" ,ax=axes[i,j],legend=True)\n",
    "        j+=1\n",
    "        if j == 3:\n",
    "            i+=1\n",
    "            j=0\n",
    "    fig.update_layout(title='30s Features', height=600)\n",
    "    return fig\n",
    "\n",
    "def loadfeature60data():\n",
    "    filepath = \"/Users/shivam/Documents/GitHub/HRVInvestigator/DataArtifacts/features_60.pkl\"\n",
    "    obj = pd.read_pickle(filepath)\n",
    "    # obj.plot(subplots=True, kind = \"kde\")\n",
    "    fig = sp.make_subplots(rows=int(obj.shape[1]/3), cols=3)\n",
    "    i=0\n",
    "    j=0\n",
    "    for col in obj.columns:\n",
    "        hist1 = px.histogram(obj[col], x=col, histnorm='density', nbins=1000)\n",
    "        fig.add_trace(hist1.data[0], row=i+1, col=j+1)\n",
    "        fig.update_xaxes(title_text=col, row=i+1, col=j+1)\n",
    "        # subobj.plot(kind=\"kde\" ,ax=axes[i,j],legend=True)\n",
    "        j+=1\n",
    "        if j == 3:\n",
    "            i+=1\n",
    "            j=0\n",
    "    fig.update_layout(title='60s Features', height=600)\n",
    "    return fig\n",
    "\n",
    "def loadfeature120data():\n",
    "    filepath = \"/Users/shivam/Documents/GitHub/HRVInvestigator/DataArtifacts/features_120.pkl\"\n",
    "    obj = pd.read_pickle(filepath)\n",
    "    # obj.plot(subplots=True, kind = \"kde\")\n",
    "    fig = sp.make_subplots(rows=int(obj.shape[1]/3), cols=3)\n",
    "    i=0\n",
    "    j=0\n",
    "    for col in obj.columns:\n",
    "        hist1 = px.histogram(obj[col], x=col, histnorm='density', nbins=1000)\n",
    "        fig.add_trace(hist1.data[0], row=i+1, col=j+1)\n",
    "        fig.update_xaxes(title_text=col, row=i+1, col=j+1)\n",
    "        # subobj.plot(kind=\"kde\" ,ax=axes[i,j],legend=True)\n",
    "        j+=1\n",
    "        if j == 3:\n",
    "            i+=1\n",
    "            j=0\n",
    "    fig.update_layout(title='120s Features', height=600)\n",
    "    return fig\n",
    "\n",
    "loadData()\n",
    "# loadfeature30data()\n",
    "main_ecg_history.current.data = main_ecg_history.current.data[0:80000:1]\n",
    "# main_ecg_history.current.mlRuns[\"truth\"] = main_ecg_history.current.mlRuns[\"truth\"][10000:20000:1]\n",
    "# main_ecg_history.current.mlRuns[\"dummy\"] = main_ecg_history.current.mlRuns[\"dummy\"][10000:20000:1]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddace795",
   "metadata": {},
   "source": [
    "## Feature Importance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64da60-75fb-414b-ba7a-020d5aca26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import components.FeatureImportance as FI\n",
    "import panel as pn\n",
    "import pickle\n",
    "pn.extension('plotly')\n",
    "import os\n",
    "\n",
    "def plot_feat_vis():\n",
    "    model_directory = \"./Models/monikit_model/\"\n",
    "    datapath = \"./DataArtifacts/\"\n",
    "    comp = FI.FeatureImportance(model_directory=model_directory, traindatapath=datapath, testdatapath=datapath)\n",
    "    # Load the feature importance from the saved file\n",
    "\n",
    "    file_name = './DataArtifacts/impfeatures.json'\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        print(\"FI file exists\")\n",
    "        comp.from_saved = True\n",
    "        return pn.pane.Plotly(comp.plot_shap(file=file_name), scaling=\"auto\")\n",
    "\n",
    "    else:\n",
    "        comp.calculate_shap()\n",
    "        # Save the SHAP values to a file\n",
    "        return pn.pane.Plotly(comp.plot_shap(file=file_name), scaling=\"auto\")\n",
    "\n",
    "row1 = pn.Row(plot_feat_vis(), height=800, sizing_mode='stretch_width')\n",
    "feature_importance_content = pn.Column(row1, height=800,\n",
    "                                       css_classes=[\"page-container\", \"main-content\"])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5abcc5d4-92c1-4d46-a36d-8a103c097f0e",
   "metadata": {},
   "source": [
    "# Processing panel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4b5cdd4-d4a2-4c96-8d9d-e32036615326",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sidebar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb0309f-14f9-41eb-bf81-02e00aa107b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d947d6-ff04-40d9-b91a-6af5eace33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Type Selector # todo add default empty\n",
    "input_type_select = pn.widgets.Select(\n",
    "    name='Select Input Type', options=[\"\",'Variable', 'File'], default=None)\n",
    "# input_type_select\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c404d1-b18a-4de4-bb65-63ae24752538",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Variable Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7ba0e-d210-498a-a21f-da9cd83a37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture store_output\n",
    "# Varable Selctor cells\n",
    "# capture the store output to select from available ipy variables\n",
    "# todo run this on selection of input type\n",
    "%store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17da564-6bcc-4e98-af33-a1090c1e1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter those to get a list \n",
    "try:\n",
    "    var_options = [x[0] for x in store_output.stdout.split(\"\\n\")[1:-1]]\n",
    "except:\n",
    "    print(\"Jupyter unavailable\")\n",
    "    var_options = []\n",
    "input_select = pn.widgets.Select(\n",
    "    name='Select Input Variable', options=var_options)\n",
    "# input_select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single file selector\n",
    "class SingleVariableFileSelectorParam(param.Parameterized):\n",
    "    relPath = './DataArtifacts/*'\n",
    "    # combine to total path\n",
    "    path = os.path.join(absPath, relPath)    \n",
    "    value = param.FileSelector(path=path, precedence=0.5, label=\"Select Filename\")\n",
    "\n",
    "\n",
    "file_processing_param = SingleVariableFileSelectorParam()\n",
    "file_select = pn.Param(file_processing_param.param[\"value\"], widgets={\n",
    "                       'Select Filename': pn.widgets.Select}, show_name=True)\n",
    "\n",
    "\n",
    "# file_select\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66f025ba-9477-4c7b-9355-329df90a6fd3",
   "metadata": {},
   "source": [
    "#### Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Input loader button\n",
    "input_loader = pn.widgets.Button(name='Import Data', button_type='primary')\n",
    "\n",
    "\n",
    "def importDataProcessing(data,name,sfreq):\n",
    "    print(\"importing data\")\n",
    "    # check if this data is a valid DataHistoryItem if so add it to the main history\n",
    "    if isinstance(data, DataHistoryItem):\n",
    "                print(\"Adding data to main history, recognised as DataHistoryItem\")\n",
    "                return main_ecg_history.addNew(data)\n",
    "    # otherwise assume that its just raw data and add it to the main history\n",
    "    else:\n",
    "        return main_ecg_history.addNewFromDict(\n",
    "            {\"data\": data, \"name\": name, \"features\": {\"sfreq\": sfreq}})\n",
    "\n",
    "def loadInput(event):\n",
    "    data = None\n",
    "    name = \"\"\n",
    "    sfreq = 0\n",
    "\n",
    "    # try:\n",
    "    if input_type_select.value == \"Variable\":\n",
    "        %store -r $input_select.value\n",
    "        data = eval(input_select.value)\n",
    "        name = input_select.value\n",
    "        \n",
    "        \n",
    "    elif input_type_select.value == \"File\":\n",
    "        fileName = file_processing_param.value\n",
    "        file = h5py.File(fileName, 'r')\n",
    "        sfreq = file[\"header\"][\"sampling_rate\"][0]\n",
    "        name = fileName.split(\"/\")[-1]\n",
    "        prefix = name.split(\".\")[0]\n",
    "        # Access the data\n",
    "        data = file[prefix][:].flatten()\n",
    "        file.close()   \n",
    "        \n",
    "        # data = np.load(fileName, allow_pickle=True)\n",
    "        \n",
    "    result = importDataProcessing(data,name,sfreq)\n",
    "    # CHANGE CONTENT OF BUTTON TO REFLECT INPUT TYPE\n",
    "    input_loader.name = \"Input Loaded: \" + \\\n",
    "        str(result.getID())\n",
    "    # except Exception as e:\n",
    "    #     input_loader.name = \"Error Loading Input\"\n",
    "    #     print(e)\n",
    "\n",
    "\n",
    "input_loader.on_click(loadInput)\n",
    "input_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input box\n",
    "input_box = pn.Card(input_type_select, '',\n",
    "                    input_loader, title=\"Quick Import\",  sizing_mode='stretch_width')\n",
    "input_box\n",
    "\n",
    "#create a watcher that replaces the input box with a new one if the input type changes\n",
    "@pn.depends(val=input_type_select.param.value, on_init=True, watch=False)\n",
    "def updateInputAdditional(event):\n",
    "    if input_type_select.value == \"Variable\":\n",
    "        input_box[1] = input_select\n",
    "    elif input_type_select.value == \"File\":\n",
    "        input_box[1] = file_select\n",
    "    else:\n",
    "        input_box[1] = \"\"\n",
    "input_type_select.param.watch(updateInputAdditional, 'value')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9808f395",
   "metadata": {},
   "source": [
    "## Active Data Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processing_active_data_selector_object = ECGHistorySelector(ecg_history=main_ecg_history, label=\"Select Active Data Object\")\n",
    "processing_active_data_selector = processing_active_data_selector_object.render()\n",
    "\n",
    "def updateActiveDataValueProcessing(*events):\n",
    "    print(\"updating active data value\")\n",
    "    processing_active_data_selector.value = main_ecg_history.current.getID()\n",
    "    \n",
    "def updateCurrentEcgHistoryProcessing(*events):\n",
    "    print(\"updating current ecghistory\")\n",
    "    main_ecg_history.current = main_ecg_history.getHistoryFromID(processing_active_data_selector.value)\n",
    "\n",
    "\n",
    "# update value if the main_ecg_data current changes\n",
    "processing_active_data_selector_watcher = main_ecg_history.param.watch(\n",
    "    updateActiveDataValueProcessing , \"current\", onlychanged=True)\n",
    "# update the current data object in the main_ecg_history object if the selector changes\n",
    "processing_active_data_selector.param.watch(\n",
    "    updateCurrentEcgHistoryProcessing, \"value\")\n",
    "# create a box for the selector\n",
    "processing_active_data_selector_box = pn.Card(\n",
    "    processing_active_data_selector, title=\"Active Data Selector\",  sizing_mode='stretch_width')\n",
    "processing_active_data_selector_box"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b94503fc-2dc1-4326-9301-792767e3d89b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Process Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240246a-050e-4517-bf6a-5f634d7ddc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data settings for the Pipeline selection\n",
    "pipelineBasePath = './Pipeline/*.py'\n",
    "pipelineModuleBasePath = \"Pipeline.\"\n",
    "pipelineObj = None\n",
    "\n",
    "# Single file selector\n",
    "\n",
    "\n",
    "class SingleCommandFileSelectorParam(param.Parameterized):\n",
    "    relPath = pipelineBasePath\n",
    "    # combine to total path \n",
    "    path = os.path.join(absPath, relPath)    \n",
    "    value = param.FileSelector(path=path, precedence=0.5)\n",
    "\n",
    "    def getFunctionName(value):\n",
    "        return value.split(\"/\")[-1].split(\".\")[0] if value != None else None\n",
    "\n",
    "\n",
    "action_param = SingleCommandFileSelectorParam\n",
    "action_select = pn.Param(action_param.param['value'], widgets={\n",
    "                         'Select Filename': pn.widgets.Select})\n",
    "\n",
    "action_select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline arguemnts Select\n",
    "# helper function to import the class part of the pipeline module\n",
    "def importName(modulename, name):\n",
    "    \"\"\" Import a named object from a module in the context of this function.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        module = __import__(modulename, globals(), locals(), [name])\n",
    "    except ImportError:\n",
    "        print(\"Error importing module: \" + modulename)\n",
    "        return None\n",
    "    return vars(module)[name]\n",
    "\n",
    "\n",
    "def renderAdditionalPipelineArguments(*events):\n",
    "    # get value from action_select\n",
    "    pipeline = None\n",
    "    if action_param.value is not None:\n",
    "        pipeline = action_param.getFunctionName(action_param.value)\n",
    "\n",
    "    if pipeline is not None:\n",
    "        pipelineModulePath = pipelineModuleBasePath + pipeline\n",
    "        pipeLineClass = importName(pipelineModulePath, pipeline)\n",
    "        if pipeLineClass is None:\n",
    "            print(\"Error importing pipeline class: \" + pipeline)\n",
    "\n",
    "        global pipelineObj\n",
    "        pipelineObj = pipeLineClass()\n",
    "        pipeLineInputs = pn.Param(pipelineObj.param)\n",
    "        return pn.Card(pipeLineInputs, title=\"Pipeline Arguments\")\n",
    "    else:\n",
    "        return pn.Card(title=\"Pipeline Arguments - Error\")\n",
    "\n",
    "\n",
    "# Install watcher for additional pipleline agruments on action select\n",
    "#PipelineArgumentWatcher = action_param.param.watch(renderAdditionalPipelineArguments,\"value\", onlychanged=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_ecg_history.addNewToExisting(\"ECG1\", data = main_ecg_history.current.data, features={\"peaks\":[0,1]}, runs = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6f05b-720a-41a8-9703-5b6c620c63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "runPipelineButton = pn.widgets.Button(\n",
    "    name='Run Command', button_type='primary')\n",
    "\n",
    "\n",
    "def runPipeline(event):\n",
    "    try:\n",
    "        if pipelineObj is not None:\n",
    "            res = pipelineObj.run(main_ecg_history.current.data)\n",
    "            # Now combine result with history\n",
    "            print(\"A\")\n",
    "            id = main_ecg_history.current.getID()\n",
    "            print(\"b\")\n",
    "            data = res[\"ecg\"] if \"ecg\" in res else None\n",
    "            print(\"c\")\n",
    "            features = res[\"features\"] if \"features\" in res else None\n",
    "            mlRuns = res[\"mlRuns\"] if \"mlRuns\" in res else None\n",
    "            print(\"d\")\n",
    "            print(features, mlRuns)\n",
    "            main_ecg_history.addNewToExisting(id, data = data, features = features, runs = None)\n",
    "            \n",
    "            main_ecg_history.param.trigger('history')\n",
    "            main_ecg_history.param.trigger('current')\n",
    "            runPipelineButton.name = \"Command Run!\"\n",
    "        else:\n",
    "            print(\"No Pipeline Object\")\n",
    "            runPipelineButton.name = \"Error Running Command\"\n",
    "    except:\n",
    "        print(\"Error running command\")\n",
    "        runPipelineButton.name = \"Error Running Command\"\n",
    "\n",
    "\n",
    "runPipelineButton.on_click(runPipeline)\n",
    "action_box = pn.Card(action_select, renderAdditionalPipelineArguments,\n",
    "                     runPipelineButton, title=\"Pipeline Selector\", sizing_mode='stretch_width')\n",
    "\n",
    "\n",
    "def updateAdditionalRenderings(*events):\n",
    "    action_box[1] = renderAdditionalPipelineArguments()\n",
    "\n",
    "\n",
    "action_param.param.watch(updateAdditionalRenderings, \"value\")\n",
    "action_box\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14863ace-2329-47ec-82aa-d1e671ad1546",
   "metadata": {},
   "source": [
    "### Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column that contains the input selector and the button\n",
    "sidebar_processing = pn.Column(input_box, processing_active_data_selector_box, action_box, css_classes=[\"sidebar\"])\n",
    "sidebar_processing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd5f9a36-3818-45a9-a4bc-045adcc1505f",
   "metadata": {},
   "source": [
    "## Main Content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "747e009f",
   "metadata": {},
   "source": [
    "### Data Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a878baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the buttons to select the correct timescale data\n",
    "time_scale_input_selector_1 = ECGHistorySelector(ecg_history=main_ecg_history, label='Select Input for Visualization 1').render()\n",
    "time_scale_input_selector_2 = ECGHistorySelector(ecg_history=main_ecg_history, label='Select Input for Visualization 2').render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadData()\n",
    "# alter last entry so we can see difference #todo remove if dummy data is no longer needed\n",
    "main_ecg_history.current.data = main_ecg_history.current.data[1000:10000:1]\n",
    "# main_ecg_history.current.mlRuns[\"truth\"] = main_ecg_history.current.mlRuns[\"truth\"][1000:10000:1]\n",
    "# main_ecg_history.current.mlRuns[\"dummy\"] = main_ecg_history.current.mlRuns[\"dummy\"][1000:10000:1]\n",
    "\n",
    "processing_window_selector = pn.widgets.EditableRangeSlider(name='Processing Window', start=0, end=10000, value=(\n",
    "    0, 10000), step=1, format=\"0[.]00\", sizing_mode='stretch_width', css_classes=[\"window1\"])\n",
    "\n",
    "\n",
    "# TODO this should be dependent on the (first input)\n",
    "@pn.depends(time_scale_input_selector_1, watch=True, on_init=True)\n",
    "def updateProcessingWindowSelector(time_scale_selector=time_scale_input_selector_1):\n",
    "    print(\"updating window selector view\")\n",
    "    # get current timescale data\n",
    "    time_scale_obj = main_ecg_history.getHistoryFromID(time_scale_selector)\n",
    "    time_scale_data = time_scale_obj.data\n",
    "\n",
    "    # get count of datapoints\n",
    "    data_count = len(time_scale_data)\n",
    "    # get sampling rate \n",
    "    if \"sfreq\" in time_scale_obj.features:\n",
    "        #rate = time_scale_obj.features[\"signalFreq\"] change when visulisation respects frequency\n",
    "        rate =1\n",
    "    else:\n",
    "        rate = 1\n",
    "    # set start and end to 0 and count/sampling rate\n",
    "    processing_window_selector.start = 0\n",
    "    processing_window_selector.end = data_count/rate\n",
    "    v1, v2 = processing_window_selector.value\n",
    "    # TODO this should be dependent on the (first input)\n",
    "    processing_window_selector.value = (max(v1, 0), min(v2, data_count/rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f688a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, Scatter\n",
    "from bokeh.models import CustomJS, TapTool\n",
    "from bokeh.models import ColumnDataSource, Column\n",
    "from bokeh.events import DoubleTap\n",
    "\n",
    "def displayTimelinePlot(time_scale_selector, timeline_window=None, signalList=[], css_classes=[]):\n",
    "   \n",
    "    # step 1 get data from input selector\n",
    "    data_stream = main_ecg_history.getHistoryFromID(time_scale_selector)\n",
    "\n",
    "    # define timestamps based on data length and sampling rate\n",
    "    freq = 1    \n",
    "    if 'sfreq' in data_stream.features:\n",
    "        freq = data_stream.features['sfreq']\n",
    "    time_stamps = np.arange(0, int(len(data_stream.data)/1))\n",
    "    # step 2 read the window selector\n",
    "    if timeline_window is None:\n",
    "        # then take the entire data stream\n",
    "        timeline_window = [0, len(data_stream.data)]\n",
    "    f_data_stream = data_stream.data\n",
    "    f_time_stamps = time_stamps\n",
    "\n",
    "    figureDataSourceDict = dict(\n",
    "        time_stamps=f_time_stamps, ECG=f_data_stream.data)\n",
    "    # check if peaks in signal\n",
    "    figureScatterSourceDict = {}\n",
    "    scatterSource = None #backup for when no peaks are found\n",
    "    def updatePeakDataOnChange(attr, old, new):\n",
    "        index = None\n",
    "        # find index of changed peak\n",
    "        #for i in range(len(new[\"peakLocations\"])):\n",
    "        #    if new[i] != old[i]:\n",
    "        #        # update the peak\n",
    "        #        index = i\n",
    "        #        break\n",
    "        #print(\"index of changed peak: \", index)\n",
    "        #print(\"old: \", str(old))\n",
    "        #print(\"new: \", str(new))\n",
    "        #data_stream.updateFromDict(new)\n",
    "        # set the new peak data\n",
    "        #data_stream.features[\"peaks\"] = \n",
    "        # trgger change\n",
    "    if \"peaks\" in data_stream.features:\n",
    "        # transform peaks so a 1 is at the peak location\n",
    "        # filter peaks so they are unique\n",
    "        figureScatterSourceDict[\"peakLocations\"] = np.unique(data_stream.features[\"peaks\"])\n",
    "        figureScatterSourceDict[\"peaks\"] = data_stream.data[figureScatterSourceDict[\"peakLocations\"]]\n",
    "        \n",
    "        scatterSource = ColumnDataSource(data=figureScatterSourceDict)\n",
    "        scatterSource.on_change('data', updatePeakDataOnChange)\n",
    "        \n",
    "\n",
    "    # define dictionary based on data\n",
    "    cds = ColumnDataSource(data=figureDataSourceDict)\n",
    "    cds.on_change('data', lambda attr, old, new: print(\"data changed\"))\n",
    "    # define tools \n",
    "    tools = 'tap,box_zoom,pan'\n",
    "    x_range=(timeline_window[0], timeline_window[1])\n",
    "    y_range =(min(f_data_stream.data), max(f_data_stream.data))\n",
    "    #create custom tap tool with python callback\n",
    "    testCallback = CustomJS(args=dict(lineData=cds, peakData=scatterSource, windowY=y_range, windowX=x_range), code=\"\"\" \n",
    "                            // check if peaks are present\n",
    "                            console.log(windowY);\n",
    "                            let event_data = cb_data;\n",
    "                            console.log(\"event data\", event_data);\n",
    "                            let posX = event_data.geometries.x;\n",
    "                            let posY = event_data.geometries.y;\n",
    "                            console.log(\"tap at x: \" + posX + \" y: \" + posY);\n",
    "                            if (peakData == null){ return; }\n",
    "                            // check if there is a close peak in peak data\n",
    "                            console.log(\"peak data\", peakData);\n",
    "                            let peakX = Array.from(peakData.data.peakLocations);\n",
    "                            let peakY = Array.from(peakData.data.peaks);\n",
    "                            // calc how large the real glyph of the peak is, so we can check against it\n",
    "                            let glyphSizeXpercent = 10/800; // 10/600 glyphsize/width\n",
    "                            let glyphSizeYpercent = 10/600; // 10/600\n",
    "                            let glyphSizeX = (windowX[1] - windowX[0]) * glyphSizeXpercent;\n",
    "                            let glyphSizeY = (windowY[1] - windowY[0]) * glyphSizeYpercent;\n",
    "                            \n",
    "                            \n",
    "                            // check if there is a peak close to the tap\n",
    "                            let i = 0\n",
    "                            let foundPeak = false;\n",
    "                            for (i; i < peakX.length; i++){\n",
    "                                // break if x is larger than posX\n",
    "                                if (peakX[i] > posX+glyphSizeX/2){ break; }\n",
    "                                // otherwise check if x is close to posX\n",
    "                                if (Math.abs(peakX[i] - posX) < glyphSizeX/2){\n",
    "                                    // check if y is close to posY\n",
    "                                    if (Math.abs(peakY[i] - posY) < glyphSizeY/2){\n",
    "                                        // then we have a peak close to the tap\n",
    "                                        // and we can remove the peak\n",
    "                                        console.log(\"removing peak at x: \" + peakX[i] + \" y: \" + peakY[i]);\n",
    "                                        console.log(peakX, peakY);\n",
    "                                        peakX.splice(i, 1);\n",
    "                                        peakY.splice(i, 1);  \n",
    "                                        console.log(peakX, peakY);                                      \n",
    "                                        foundPeak = true;\n",
    "                                        break;\n",
    "                                        \n",
    "                                        }\n",
    "                                        else{\n",
    "                                        console.log(Math.abs(peakY[i] - posY), glyphSizeY/2);\n",
    "                                        }\n",
    "                                    }\n",
    "                                    else{\n",
    "                                    console.log(Math.abs(peakX[i] - posX), glyphSizeX/2);\n",
    "                                }\n",
    "                                    \n",
    "                                }\n",
    "                                \n",
    "                                \n",
    "                                        \n",
    "                             \n",
    "                            // otherwise we add a new peak at the point just after element i\n",
    "                            if (!foundPeak){\n",
    "                            peakX.splice(i, 0, posX);\n",
    "                            peakY.splice(i, 0, posY);\n",
    "                            }\n",
    "                            \n",
    "                                \n",
    "                            \n",
    "                            console.log('tap tool callback')                            \n",
    "                            peakData.data = {peaks: peakY, peakLocations: peakX}\n",
    "                            peakData.change.emit();                           \n",
    "                            \"\"\")\n",
    "    cTapTool = TapTool(callback=testCallback)\n",
    "    \n",
    "    p = figure(sizing_mode='stretch_width', title='', x_range=x_range, y_range=y_range, \n",
    "               css_classes=css_classes, tools= [cTapTool, 'box_zoom', 'pan'], plot_width=800, plot_height=300)\n",
    "\n",
    "    p.line('time_stamps', 'ECG', source=cds)\n",
    "    if len(figureScatterSourceDict) > 0:\n",
    "        # register a callback vent for when a user clicks a scatter point\n",
    "        updateScatterSelection = CustomJS(args=dict(source= scatterSource ), \n",
    "                                          code=\"\"\"\n",
    "                let inds = cb_obj.indices;\n",
    "                let d1 = source.data; \n",
    "            \n",
    "                d1['peaks'] = Array.from(d1['peaks']);\n",
    "                let d2 = {}\n",
    "                d2['peakLocations'] = []\n",
    "                d2['peaks'] = []\n",
    "                \n",
    "                for (let i = 0; i < inds.length; i++) {\n",
    "                    d2['peakLocations'].push(d1['peakLocations'][inds[i]])\n",
    "                    d2['peaks'].push(d1['peaks'][inds[i]])\n",
    "                }\n",
    "                for (let elem of d2['peakLocations']) {\n",
    "                    const index = d1['peakLocations'].indexOf(elem);\n",
    "                    if (index > -1) { // only splice array when item is found\n",
    "                    d1['peakLocations'].splice(index, 1); //2nd parameter means remove one item only\n",
    "                    d1['peaks'].splice(index, 1); //2nd parameter means remove one item only\n",
    "                    }\n",
    "                }\n",
    "                source.selected.indices = [] // reset selections\n",
    "                source.change.emit();\n",
    "                \n",
    "            \"\"\")\n",
    "                      \n",
    "        \n",
    "        scatterSource.selected.js_on_change('indices', updateScatterSelection)\n",
    "        #scatterSource.selected.on_change('indices', testCallback)\n",
    "        # scatterplot with circle indicators of peaks\n",
    "        p.scatter('peakLocations', 'peaks', source= scatterSource , marker=\"circle\", size=10, color=\"red\")\n",
    "\n",
    "    # render pane\n",
    "    bk_pane = pn.pane.Bokeh(p, css_classes=css_classes,\n",
    "                            sizing_mode='stretch_width')\n",
    "    return bk_pane\n",
    "\n",
    "\n",
    "@pn.depends(time_scale_input_selector_1, processing_window_selector)\n",
    "def  buildTimelineVis1(time_scale_selector=time_scale_input_selector_1, timeline_window=processing_window_selector):\n",
    "    \n",
    "    try:\n",
    "        res = displayTimelinePlot(time_scale_selector, timeline_window, css_classes=[\"vis1\"])\n",
    "        #res = None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        res = None\n",
    "    return res if res is not None else pn.pane.Markdown(\"No data available\")\n",
    "\n",
    "\n",
    "@pn.depends(time_scale_input_selector_2, processing_window_selector)\n",
    "def buildTimelineVis2(time_scale_selector=time_scale_input_selector_2, timeline_window=processing_window_selector):\n",
    "    res = displayTimelinePlot(time_scale_selector, timeline_window, css_classes=[\"vis2\"])\n",
    "    #res = None\n",
    "    return res if res is not None else pn.pane.Markdown(\"No data available\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd3d0f40",
   "metadata": {},
   "source": [
    "### Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484fee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_processing = pn.Column(css_classes=[\"main-content\"])\n",
    "top_row_1 = pn.Row(time_scale_input_selector_1, height=60, sizing_mode='fixed')\n",
    "top_row_2 = pn.Row(buildTimelineVis1, sizing_mode='stretch_width')\n",
    "middle_row = pn.Row(processing_window_selector, sizing_mode='stretch_width')\n",
    "bot_row_1 = pn.Row(time_scale_input_selector_2, sizing_mode='fixed', height=60)\n",
    "bot_row_2 = pn.Row(buildTimelineVis2, sizing_mode='stretch_width')\n",
    "main_processing.append(top_row_1)\n",
    "main_processing.append(top_row_2)\n",
    "main_processing.append(middle_row)\n",
    "main_processing.append(bot_row_1)\n",
    "main_processing.append(bot_row_2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "898e12aa",
   "metadata": {},
   "source": [
    "## Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99673bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_panel = pn.Row(\n",
    "    sidebar_processing, main_processing, css_classes=[\"page-container\"])\n",
    "#processing_panel = pn.Row(sidebar_processing,css_classes = [\"page-container\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea1cb790-b0e1-4829-a340-5ecfe42c6879",
   "metadata": {},
   "source": [
    "# Insights Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.insights.shared import InsightsWindowSelector, InsightsTab, InsightsFileSelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.insights.timeDomainVis import InsightsTimeDomainTab, InsightsTimeDomainStats, InsightsTimeDomainVis\n",
    "\n",
    "\n",
    "def render_insights_windowSelector():\n",
    "    # a time scale data selector\n",
    "    # TODO bind wether this is greyed out to value of inisigths file selector\n",
    "    return pn.widgets.IntRangeSlider(name=\"Input Window\", start=0, end=100, value=(0, 100), step=1)\n",
    "\n",
    "\n",
    "def render_insights_frequency_domain_vis():\n",
    "    return\n",
    "\n",
    "def render_insights_features_30():\n",
    "    return pn.Row(pn.pane.Plotly(loadfeature30data(), scaling=\"auto\"))\n",
    "\n",
    "def render_insights_features_60():\n",
    "    return pn.Row(pn.pane.Plotly(loadfeature60data(), scaling=\"auto\"))\n",
    "\n",
    "def render_insights_features_120():\n",
    "    return pn.Row(pn.pane.Plotly(loadfeature120data(), scaling=\"auto\"))\n",
    "\n",
    "def render_insights_frequency_domain_side():\n",
    "    return\n",
    "\n",
    "\n",
    "def render_insights_frequency_domain():\n",
    "    return pn.Row(render_insights_frequency_domain_side, render_insights_frequency_domain_vis)\n",
    "\n",
    "\n",
    "def render_insights_nonlinear_domain_vis():\n",
    "    return\n",
    "\n",
    "\n",
    "def render_insights_nonlinear_domain_side():\n",
    "    return\n",
    "\n",
    "\n",
    "def render_insights_nonlinear_domain():\n",
    "    return pn.Row(render_insights_nonlinear_domain_side, render_insights_nonlinear_domain_vis)\n",
    "\n",
    "\n",
    "def render_insights_timevar_domain_vis():\n",
    "    return\n",
    "\n",
    "\n",
    "def render_insights_timevar_domain_side():\n",
    "    return\n",
    "\n",
    "\n",
    "def render_insights_timevar_domain():\n",
    "    return pn.Row(render_insights_timevar_domain_side, render_insights_timevar_domain_vis)\n",
    "\n",
    "\n",
    "def render_insights_panel_elem():\n",
    "    # Row 1\n",
    "    fileSelector = InsightsFileSelector(main_ecg_history)\n",
    "    windowSelector = InsightsWindowSelector(fileSelector, main_ecg_history)\n",
    "\n",
    "    # timeDomainButton = pn.widgets.Button(\n",
    "    #     name=\"Time-Domain\", button_type=\"primary\", width=120)\n",
    "    feature30Button = pn.widgets.Button(\n",
    "        name=\"30s Features\", button_type=\"primary\", width=120)\n",
    "    feature60Button = pn.widgets.Button(\n",
    "        name=\"60s Features\", button_type=\"primary\", width=120)\n",
    "    feature120Button = pn.widgets.Button(\n",
    "        name=\"120s Features\", button_type=\"primary\", width=120)\n",
    "    timeDom = InsightsTimeDomainTab(fileSelectorRef=fileSelector,\n",
    "                                    windowSelectorRef=windowSelector,\n",
    "                                    data_history=main_ecg_history)\n",
    "    # freqDomainButton = pn.widgets.Button(\n",
    "    #     name=\"Frequency-Domain\", button_type=\"default\", width=120)\n",
    "    # nonlinDomainButton = pn.widgets.Button(\n",
    "    #     name=\"Nonlinear-Domain\", button_type=\"default\", width=120)\n",
    "    # timeVarDomainButton = pn.widgets.Button(\n",
    "    #     name=\"Time-Varying-Domain\", button_type=\"default\", width=120)\n",
    "    # buttonList = [timeDomainButton, freqDomainButton,\n",
    "    #               nonlinDomainButton, timeVarDomainButton]\n",
    "    buttonList = [feature30Button, feature60Button,\n",
    "                  feature120Button]\n",
    "    \n",
    "    selectorList = [fileSelector.getRender, windowSelector.getRender]\n",
    "\n",
    "    def restoreButtonStates():\n",
    "        for button in buttonList:\n",
    "            button.button_type = \"default\"\n",
    "\n",
    "    \n",
    "    top_row = pn.FlexBox(pn.Row(*buttonList), css_classes=[\"top-row\"], justify_content=\"space-between\", flex_wrap=\"nowrap\")\n",
    "    main_row = pn.Row(render_insights_features_30)\n",
    "    # register switches on button press\n",
    "\n",
    "    # def switchToTimeDomain(event):\n",
    "    #     restoreButtonStates()\n",
    "    #     timeDomainButton.button_type = \"primary\"\n",
    "    #     main_row[0].loading = True\n",
    "    #     main_row[0] = timeDom.getRender\n",
    "    #     main_row[0].loading = False\n",
    "\n",
    "    # def switchToFreqDomain(event):\n",
    "    #     restoreButtonStates()\n",
    "    #     freqDomainButton.button_type = \"primary\"\n",
    "    #     main_row[0].loading = True\n",
    "    #     main_row[0] = render_insights_frequency_domain\n",
    "    #     main_row[0].loading = False\n",
    "\n",
    "    # def switchToNonLinDomain(event):\n",
    "    #     restoreButtonStates()\n",
    "    #     nonlinDomainButton.button_type = \"primary\"\n",
    "    #     main_row[0].loading = True\n",
    "    #     main_row[0] = render_insights_nonlinear_domain\n",
    "    #     main_row[0].loading = False\n",
    "\n",
    "    # def switchToTimeVarDomain(event):\n",
    "    #     restoreButtonStates()\n",
    "    #     timeVarDomainButton.button_type = \"primary\"\n",
    "    #     main_row[0].loading = True\n",
    "    #     main_row[0] = render_insights_timevar_domain\n",
    "    #     main_row[0].loading = False\n",
    "\n",
    "    def switchToFeature30(event):\n",
    "        restoreButtonStates()\n",
    "        feature30Button.button_type = \"primary\"\n",
    "        main_row[0].loading = True\n",
    "        main_row[0] = render_insights_features_30\n",
    "        main_row[0].loading = False\n",
    "\n",
    "    def switchToFeature60(event):\n",
    "        restoreButtonStates()\n",
    "        feature60Button.button_type = \"primary\"\n",
    "        main_row[0].loading = True\n",
    "        main_row[0] = render_insights_features_60\n",
    "        main_row[0].loading = False\n",
    "\n",
    "    def switchToFeature120(event):\n",
    "        restoreButtonStates()\n",
    "        feature120Button.button_type = \"primary\"\n",
    "        main_row[0].loading = True\n",
    "        main_row[0] = render_insights_features_120\n",
    "        main_row[0].loading = False\n",
    "\n",
    "    # register clicks\n",
    "    # timeDomainButton.on_click(switchToTimeDomain)\n",
    "    # freqDomainButton.on_click(switchToFreqDomain)\n",
    "    # nonlinDomainButton.on_click(switchToNonLinDomain)\n",
    "    # timeVarDomainButton.on_click(switchToTimeVarDomain)\n",
    "\n",
    "    feature30Button.on_click(switchToFeature30)\n",
    "    feature60Button.on_click(switchToFeature60)\n",
    "    feature120Button.on_click(switchToFeature120)\n",
    "\n",
    "    # render the window selector param, so it has a value_throttled property\n",
    "    res = pn.Column(top_row, main_row)\n",
    "    # file selector\n",
    "    # domain Selector\n",
    "    # Row 2\n",
    "    # Stats\n",
    "    # Visualisation\n",
    "    return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "231205d7",
   "metadata": {},
   "source": [
    "### Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88947fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_panel = pn.Column(render_insights_panel_elem(\n",
    "), css_classes=[\"page-container\"])\n",
    "#insights_panel\n",
    "\n",
    "feature_importance_panel = pn.Column(feature_importance_content, css_classes=[\"page-container\"])\n",
    "#feature_importance_panel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0986ceb-45fb-4062-83ed-49602fc1a971",
   "metadata": {},
   "source": [
    "# ML Panel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa606aa3",
   "metadata": {},
   "source": [
    "## Top Nav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de84299d",
   "metadata": {},
   "source": [
    "### Input Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the buttons to select the correct timescale data\n",
    "time_scale_input_selector_ml_object = ECGHistorySelector(main_ecg_history, label = \"Select Input\")\n",
    "time_scale_input_selector_ml = time_scale_input_selector_ml_object.render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single transformation File Selector\n",
    "class SingleTransformationScriptSelectorParam(param.Parameterized):\n",
    "    relPath = './MLTransformation/*'\n",
    "    # combine to total path \n",
    "    path = os.path.join(absPath, relPath)    \n",
    "    value = param.FileSelector(path=path, precedence=0.5, label=\"Select Transformation Script\")\n",
    "\n",
    "\n",
    "\n",
    "ml_transformation_param = SingleTransformationScriptSelectorParam()\n",
    "ml_transformation_select = pn.Param(ml_transformation_param.param[\"value\"], widgets={\n",
    "                       'Select Filename': pn.widgets.Select}, show_name=False)\n",
    "\n",
    "\n",
    "def getFunctionName(value):\n",
    "    return value.split(\"/\")[-1].split(\".\")[0] if value != None else None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "getFunctionName(ml_transformation_param.value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "194765b6",
   "metadata": {},
   "source": [
    "### Model Selector + Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ac933c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2479803525.py, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [2], line 59\u001b[0;36m\u001b[0m\n\u001b[0;31m    prediction_dict = {transformationName +\"_\"+str(getFunctionName(file_param.value)): prediction}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# model eval type -> TODO this should be a dropdown\n",
    "import torch\n",
    "model_eval_type = \"torch\"\n",
    "\n",
    "\n",
    "class SingleModelFileSelectorParam(param.Parameterized):\n",
    "    relPath = './Models/*'\n",
    "    # combine to total path \n",
    "    path = os.path.join(absPath, relPath)        \n",
    "    value = param.FileSelector(path=path, precedence=0.5, default=None)\n",
    "    \n",
    "\n",
    "\n",
    "file_param = SingleModelFileSelectorParam()\n",
    "file_select_ml = pn.Param(file_param.param[\"value\"], widgets={\n",
    "                          'Select Filename': pn.widgets.Select}, show_name=False)\n",
    "\n",
    "buttonEvalML = pn.widgets.Button(\n",
    "    name='Evaluate with Model', button_type='primary')\n",
    "\n",
    "transformationBasePath = './MLTransformation/*.py'\n",
    "transformationModuleBasePath = \"MLTransformation.\"\n",
    "transformationObj = None\n",
    "\n",
    "def evaluateModel(event):\n",
    "    # try:\n",
    "        # get data from input selector\n",
    "    print(\"evaluateModelNew\")\n",
    "    history_id = time_scale_input_selector_ml.value\n",
    "    print(\"history_id: \" + history_id)\n",
    "    if history_id == None:\n",
    "        print(\"Error: history_id is None\")\n",
    "        return\n",
    "    data = main_ecg_history.getHistoryFromID(\n",
    "        history_id)   \n",
    "    print(\"data: \")   \n",
    "    data = data.data\n",
    "    print(\"data_len: \" + str(len(data)))\n",
    "    print(getFunctionName(ml_transformation_param.value))\n",
    "    prediction = None\n",
    "    \n",
    "    print(ml_transformation_param.value)\n",
    "    transformationName = None\n",
    "    if ml_transformation_param.value!=None:\n",
    "        transformationName = getFunctionName(ml_transformation_param.value)\n",
    "    if transformationName!=None:\n",
    "        \n",
    "        print(\"transformationName: \" + transformationName)\n",
    "        transformationModulePath = transformationModuleBasePath + transformationName\n",
    "        print(\"transformationModulePath: \" + transformationModulePath)\n",
    "        transformationClass = importName(transformationModulePath, transformationName)\n",
    "        if  transformationClass is None:            \n",
    "            print(\"Error importing  transformation class: \" +  transformationName)\n",
    "\n",
    "        global transformationObj\n",
    "        transformationObj = transformationClass()\n",
    "    \n",
    "        prediction = transformationObj.run()\n",
    "        prediction_dict = {transformationName +\"_\"+str(getFunctionName(file_param.value)): prediction}\n",
    "        print(\"prediction_dict: \" + str(prediction_dict))\n",
    "        # add prediction to history\n",
    "        res = main_ecg_history.addNewToExisting(history_id, data= None, features=None,runs=prediction_dict )\n",
    "        print(res.mlRuns.keys())\n",
    "        main_ecg_history.param.trigger('history')\n",
    "        main_ecg_history.param.trigger('current')\n",
    "        print(\"HERE\")\n",
    "        buttonEvalML.name = \"Model Evaluation: \" + str(res.getID())\n",
    "    # except:\n",
    "    #     buttonEvalML.name = \"Error Running Model Evaluation\"\n",
    "    #     print(\"Error running model evaluation\")\n",
    "    \n",
    "\n",
    "buttonEvalML.on_click(evaluateModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad680722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to evaluate model\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_self_attention'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/shivam/Documents/GitHub/HRVInvestigator/HRVInvestigatorDashboard.ipynb Cell 53\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shivam/Documents/GitHub/HRVInvestigator/HRVInvestigatorDashboard.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mMLTransformation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmonikit\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmml\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shivam/Documents/GitHub/HRVInvestigator/HRVInvestigatorDashboard.ipynb#Y136sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m mml\u001b[39m.\u001b[39mmonikit()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shivam/Documents/GitHub/HRVInvestigator/HRVInvestigatorDashboard.ipynb#Y136sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m preds \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49mrun(model_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/Users/shivam/Documents/GitHub/HRVInvestigator/Models/monikit_model/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shivam/Documents/GitHub/HRVInvestigator/HRVInvestigatorDashboard.ipynb#Y136sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(preds)\n",
      "File \u001b[0;32m~/Documents/GitHub/HRVInvestigator/MLTransformation/monikit.py:27\u001b[0m, in \u001b[0;36mmonikit.run\u001b[0;34m(self, model_file)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mstarting to evaluate model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m testdatapath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../DataArtifacts/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m model \u001b[39m=\u001b[39m Model\u001b[39m.\u001b[39;49mload_by_path(model_file)\n\u001b[1;32m     28\u001b[0m test_feattab \u001b[39m=\u001b[39m FeatureTable(testdatapath)\n\u001b[1;32m     29\u001b[0m test_data \u001b[39m=\u001b[39m test_feattab\u001b[39m.\u001b[39mget_prediction_data(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/HRVInvestigator/components/monipy/monipy/models/Model.py:742\u001b[0m, in \u001b[0;36mModel.load_by_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    740\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_by_path\u001b[39m(path: \u001b[39mstr\u001b[39m):  \u001b[39m# TODO: return type should be Model\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mmonikit_model.pkl\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 742\u001b[0m         model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m    744\u001b[0m     model\u001b[39m.\u001b[39mload_internals(path)\n\u001b[1;32m    745\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Documents/GitHub/HRVInvestigator/components/monipy/monipy/models/ResnetAttTF.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mBaseClassTF\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseClassTF\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmonipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresnet\u001b[39;00m \u001b[39mimport\u001b[39;00m build_model_resnet_att\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmonipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutils_metrics\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfa\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/HRVInvestigator/components/monipy/monipy/models/resnet.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_self_attention\u001b[39;00m \u001b[39mimport\u001b[39;00m SeqSelfAttention\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Flatten\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_model_resnet\u001b[39m(input_shape\u001b[39m=\u001b[39m(\u001b[39m55\u001b[39m, \u001b[39m30\u001b[39m), nb_classes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_self_attention'"
     ]
    }
   ],
   "source": [
    "# import MLTransformation.monikit as mml\n",
    "# eval = mml.monikit()\n",
    "# preds = eval.run(model_file=\"/Users/shivam/Documents/GitHub/HRVInvestigator/Models/monikit_model/\")\n",
    "# print(preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "681f7170",
   "metadata": {},
   "source": [
    "## Main Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dfc56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_window_selector = pn.widgets.EditableRangeSlider(name='Evaluation Window', start=0, end=100, value=(\n",
    "    0, 100), step=1, format=\"0[.]00\", sizing_mode='stretch_width')\n",
    "\n",
    "eval_file_selector_1 = ECGHistorySelector(main_ecg_history, label = \"Select Evaluation File\").render()\n",
    "eval_run_selector_1 = ECGRunSelector(main_ecg_history, label = \"Select Evaluation Run\", hook = eval_file_selector_1).render()\n",
    "eval_file_selector_2= ECGHistorySelector(main_ecg_history, label = \"Select Evaluation File\").render()\n",
    "eval_run_selector_2 = ECGRunSelector(main_ecg_history, label = \"Select Evaluation Run\", hook = eval_file_selector_2).render()\n",
    "\n",
    "\n",
    "@pn.depends(eval_file_selector_1, watch=True)\n",
    "def updateProcessingWindowSelectorML(time_scale_selector=time_scale_input_selector_ml):\n",
    "    print(\"updating window selector view\")\n",
    "    # get current timescale data\n",
    "    time_scale_data = main_ecg_history.getHistoryFromID(\n",
    "        time_scale_selector).data\n",
    "\n",
    "    # get count of datapoints\n",
    "    data_count = len(time_scale_data)\n",
    "    # get sampling rate #TODO \n",
    "    rate = 1\n",
    "    # set start and end to 0 and count/sampling rate\n",
    "    eval_window_selector.start = 0\n",
    "    eval_window_selector.end = data_count/rate\n",
    "    v1, v2 = eval_window_selector.value\n",
    "    \n",
    "    eval_window_selector.value = (max(v1, 0), min(v2, data_count/rate))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b77fc4",
   "metadata": {},
   "source": [
    "### Model 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cece84fe",
   "metadata": {},
   "source": [
    "#### Timeline Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc49be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def buildEvalTimelineVis(time_scale_selector=time_scale_input_selector_ml, run=eval_run_selector_1, timeline_window=eval_window_selector):\n",
    "    # return a bokeh Pane of a plot using both the data and the run information\n",
    "    \n",
    "    #get data\n",
    "    data_stream = main_ecg_history.getHistoryFromID(time_scale_selector)\n",
    "    \n",
    "    #define frequency and timestamps\n",
    "    req = 1    \n",
    "    if 'sFreq' in data_stream.features:\n",
    "        freq = data_stream.features['sFreq']\n",
    "    time_stamps = np.arange(0, int(len(data_stream.data)/1))\n",
    "    \n",
    "    #access timeline window\n",
    "    timeline= [0,1]\n",
    "    if timeline_window is None:\n",
    "        # then take the entire data stream\n",
    "        timeline = [0, len(data_stream.data)]\n",
    "    else:\n",
    "        timeline = timeline_window\n",
    "        \n",
    "    # create og data source dict\n",
    "    figureDataSourceDict = dict(\n",
    "        time_stamps=time_stamps, ECG=data_stream.data)\n",
    "    \n",
    "    # check if truth is in mlRuns\n",
    "    if 'truth' in data_stream.mlRuns:\n",
    "        figureDataSourceDict['truth'] = data_stream.mlRuns['truth']\n",
    "    if run is not None:\n",
    "        # check if run is in mlRuns\n",
    "        if run in data_stream.mlRuns:\n",
    "            figureDataSourceDict[\"run\"] = data_stream.mlRuns[run]\n",
    "            \n",
    "    # define dictionary based on data\n",
    "    cds = ColumnDataSource(data=figureDataSourceDict)\n",
    "    # define tools \n",
    "    tools = 'tap,box_zoom,pan'\n",
    "    # define figure\n",
    "    p = figure(plot_width=800, plot_height=400, tools=tools, title=\"ML Evaluation\", x_axis_label='Time (s)', x_range=(timeline[0], timeline[1]))\n",
    "    # add line for ECG\n",
    "    p.line(x='time_stamps', y='ECG', source=cds, line_width=2, line_alpha=0.8, color='blue')\n",
    "    # add scatter for truth\n",
    "    p.scatter(x='time_stamps', y='truth', source=cds, color='green')\n",
    "    # add scatter for run\n",
    "    p.scatter(x='time_stamps', y='run', source=cds, color='red')\n",
    "    \n",
    "    bk_pane = pn.pane.Bokeh(p,\n",
    "                            sizing_mode='stretch_width')\n",
    "    return bk_pane\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d1e4752",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19fb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "def mlEvalVisStats(sel_file=eval_file_selector_1, sel_run=eval_run_selector_1, sel_window=eval_window_selector):\n",
    "    try:\n",
    "        # check if file exists\n",
    "        \n",
    "        if sel_file is None  or sel_run is None or sel_window is None:\n",
    "            print(sel_file is None, sel_run is None, sel_window is None)\n",
    "            return pn.pane.Markdown(\"Stats unavailable,Please select a file, run and window\", style={'font-family': \"serif\"})\n",
    "        \n",
    "        data_obj = main_ecg_history.getHistoryFromID(sel_file)\n",
    "        \n",
    "        if (sel_run not in data_obj.mlRuns or \"truth\" not in data_obj.mlRuns.keys()):\n",
    "            return pn.pane.Markdown(\"Ground Truth or Prediction Unavailable\", style={'font-family': \"serif\"})\n",
    "        \n",
    "        start = max(0, sel_window[0])\n",
    "        end = min(len(data_obj.data), sel_window[1])\n",
    "        y_true = data_obj.mlRuns[\"truth\"][start:end]\n",
    "        y_pred = data_obj.mlRuns[sel_run][start:end]\n",
    "        \n",
    "        conf = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "        # calculate accurcy from confusion matrix \n",
    "        accuracy = (conf.iloc[0,0] + conf.iloc[1,1]) / conf.sum().sum()\n",
    "\n",
    "        confusion = conf\n",
    "        confusion_matrix_rep = pn.widgets.DataFrame(\n",
    "            confusion, autosize_mode='fit_columns', width=300)\n",
    "        accuracy_rep = pn.pane.Markdown(\n",
    "            'Accuracy:' + str(accuracy), style={'font-family': \"serif\"})\n",
    "        return pn.Card(accuracy_rep, confusion_matrix_rep, title=\"Stats\")   \n",
    "    except:\n",
    "        return pn.pane.Markdown(\"Error while rendering Stats\", style={'font-family': \"serif\"})\n",
    "\n",
    "\n",
    "@pn.depends(eval_file_selector_1,eval_run_selector_1, eval_window_selector)\n",
    "def buildEvalVis1(file_selector=time_scale_input_selector_1, run_selector = eval_run_selector_1, timeline_window=eval_window_selector):\n",
    "    \n",
    "    try:\n",
    "        res = pn.Row(mlEvalVisStats(file_selector,run_selector, timeline_window), \n",
    "                     buildEvalTimelineVis(file_selector, run_selector, timeline_window))\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        res = pn.pane.Markdown(\"No Visualization available. Error while rendering\")\n",
    "    return res if res is not None else pn.pane.Markdown(\"No data available\")\n",
    "\n",
    "\n",
    "@pn.depends(eval_file_selector_2,eval_run_selector_2, eval_window_selector)\n",
    "def buildEvalVis2(file_selector=time_scale_input_selector_1, run_selector = eval_run_selector_1, timeline_window=eval_window_selector):\n",
    "    try:\n",
    "        res = pn.Row(mlEvalVisStats(file_selector,run_selector, timeline_window), \n",
    "                     buildEvalTimelineVis(file_selector, run_selector, timeline_window))\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        res = pn.pane.Markdown(\"No Visualization available. Error while rendering\")\n",
    "    return res if res is not None else pn.pane.Markdown(\"No data available\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f09cfd4",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "546362b2",
   "metadata": {},
   "source": [
    "### Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_row1 = pn.Row(time_scale_input_selector_ml,ml_transformation_select, file_select_ml,\n",
    "                 buttonEvalML, sizing_mode='stretch_width')\n",
    "ml_row1_5 = pn.Row(eval_file_selector_1,eval_run_selector_1, sizing_mode='stretch_width')\n",
    "ml_row2 = buildEvalVis1\n",
    "# ml_row3 = pn.Row(eval_window_selector, sizing_mode='stretch_width')\n",
    "# ml_row3_5 = pn.Row(eval_file_selector_2,eval_run_selector_2, sizing_mode='stretch_width')\n",
    "# ml_row4 = buildEvalVis2\n",
    "\n",
    "ml_panel = pn.Column(ml_row1,ml_row1_5, ml_row2, \n",
    "                     css_classes=[\"page-container\", \"main-content\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "550c2908",
   "metadata": {},
   "source": [
    "# Data Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Selector\n",
    "# TODO need dummy model to test this and perhaps remove the time series restriction\n",
    "data_selector = pn.widgets.Select(name='Select Active Input', options=[x.getID(\n",
    ") for x in main_ecg_history.history], value=main_ecg_history.current.getID())\n",
    "\n",
    "# Data Selector Watcher\n",
    "\n",
    "\n",
    "def updateOption(*events):\n",
    "    data_selector.options = [x.getID() for x in main_ecg_history.history]\n",
    "# Data Active Watcher\n",
    "\n",
    "\n",
    "def updateActiveData(*events):\n",
    "    data_selector.value = main_ecg_history.current.getID()\n",
    "\n",
    "\n",
    "def updateActiveSelectedData(*events):\n",
    "    print(\"updating active data\")\n",
    "    main_ecg_history.current = main_ecg_history.getHistoryFromID(\n",
    "        data_selector.value)\n",
    "\n",
    "\n",
    "dataUpdateWatcher = data_selector.param.watch(\n",
    "    updateActiveSelectedData, \"value\", onlychanged=False)\n",
    "dataOptionUpdateWatcher = main_ecg_history.param.watch(\n",
    "    updateOption, \"history\", onlychanged=False)\n",
    "dataOptionUpdateWatcher = main_ecg_history.param.watch(\n",
    "    updateActiveData, \"history\", onlychanged=False)\n",
    "\n",
    "data_selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cf6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Inspector and rename\n",
    "# TODO get back here when data Structure is redone\n",
    "@pn.depends(data_selector)\n",
    "def showCurrentData(*events):\n",
    "    print(\"selected data has changed\")\n",
    "    return pn.Param(main_ecg_history.current.param, widgets={\n",
    "        'data': {'widget_type': pn.widgets.ArrayInput, 'disabled': True},\n",
    "        'name': {'widget_type': pn.widgets.TextInput},\n",
    "\n",
    "\n",
    "    }, parameters=['data', 'name', \"features\"], name=\"Data Inspector\", sizing_mode='stretch_width', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Saver and Importer\n",
    "dataPath = \"./DataArtifacts/\"\n",
    "saveDataButton = pn.widgets.Button(name='Save Data', button_type='primary')\n",
    "loadDataButton = pn.widgets.Button(name='Load Data', button_type='primary')\n",
    "loadDataInput = pn.widgets.FileInput(accept='.pkl', multiple=False)\n",
    "saveData = None\n",
    "\n",
    "\n",
    "def saveData(*events):\n",
    "    data_obj = main_ecg_history.current\n",
    "    name = data_obj.getID()\n",
    "    # pickle the data\n",
    "    with open(dataPath + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(main_ecg_history.current.getSaveDict(), f)\n",
    "\n",
    "    global savedData \n",
    "    savedData= main_ecg_history.current.getSaveDict()\n",
    "    %store savedData\n",
    "    saveDataButton.name = \"Data Saved\"\n",
    "\n",
    "\n",
    "def loadData(*events):\n",
    "    try:\n",
    "        # get the file name\n",
    "        filename = loadDataInput.filename    \n",
    "        \n",
    "        if filename is None:\n",
    "            loadDataButton.name = \"Error: Set Filename\"\n",
    "        \n",
    "        # load the data\n",
    "        with open(dataPath + filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            main_ecg_history.addNewFromDict(data)\n",
    "        # add the data to the history\n",
    "\n",
    "        loadDataButton.name = \"Data Loaded\"\n",
    "    except:\n",
    "        loadDataButton.name = \"Error: make sure to load from DataArtifacts folder\"\n",
    "        \n",
    "\n",
    "\n",
    "saveDataButton.on_click(saveData)\n",
    "loadDataButton.on_click(loadData)\n",
    "\n",
    "dataLoaderArea = pn.Row(saveDataButton, loadDataButton, loadDataInput)\n",
    "dataLoaderArea\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbf34320",
   "metadata": {},
   "source": [
    "## Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aeb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from panel.interact import interact\n",
    "data_panel = pn.Column(data_selector, showCurrentData, dataLoaderArea, css_classes=[\n",
    "                       \"page-container\", \"main-content\"])\n",
    "\n",
    "\n",
    "def updateMainHistory(*events):\n",
    "    \"\"\"This function is used to update the main history when the data inside is changed, by emitting a trigger event on the history, when an element is changed\n",
    "    \"\"\"\n",
    "    main_ecg_history.history = main_ecg_history.history\n",
    "    main_ecg_history.param.trigger(\"history\")\n",
    "    print(\"updating main history\" + str(main_ecg_history.current.getID()))\n",
    "\n",
    "\n",
    "main_ecg_history.current.param.watch(\n",
    "    updateMainHistory, [\"name\", \"features\", 'data'], onlychanged=False)\n",
    "data_panel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5e7d9bd",
   "metadata": {},
   "source": [
    "# Console Panel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784557d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "console_terminal = pn.widgets.Terminal(\n",
    "    options={\"cursorBlink\": True}, height=500, width=500, sizing_mode='stretch_width')\n",
    "sys.stdout = console_terminal\n",
    "print(\"Welcome to the ECG Console\")\n",
    "# console_terminal\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a178447",
   "metadata": {},
   "source": [
    "## Assembly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "console_panel = pn.Column(console_terminal, css_classes=[\n",
    "                          \"page-container\", \"main-content\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1d9ce8c-f61f-4c95-aac2-4dd1731b1e66",
   "metadata": {},
   "source": [
    "# Orchestration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1b8af7c",
   "metadata": {},
   "source": [
    "## Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# instead of tabs use buttons that change the layout\n",
    "# create a top bar with a button for each panel with data and console beeing rightbound\n",
    "process_button = pn.widgets.Button(\n",
    "    name='Process', button_type='primary', width=150)\n",
    "insights_button = pn.widgets.Button(\n",
    "    name='Insights', button_type='light', width=150)\n",
    "machine_learning_button = pn.widgets.Button(\n",
    "    name='Machine Learning', button_type='light', width=150)\n",
    "feature_importance_button = pn.widgets.Button(\n",
    "    name='Feature Importance', button_type='light', width=150)\n",
    "data_button = pn.widgets.Button(\n",
    "    name='Data', button_type='light', align='end', width=150)\n",
    "console_button = pn.widgets.Button(\n",
    "    name='Console', button_type='light', align='end', width=150)\n",
    "buttonList = [process_button, insights_button,\n",
    "              machine_learning_button,feature_importance_button, data_button, console_button]\n",
    "\n",
    "\n",
    "def resetAllButtons():\n",
    "    for button in buttonList:\n",
    "        button.button_type = \"default\"\n",
    "\n",
    "\n",
    "top_bar = pn.FlexBox(pn.Row(process_button, insights_button, machine_learning_button, feature_importance_button), pn.Row(\n",
    "    data_button, console_button), justify_content='space-between', sizing_mode='stretch_width', css_classes=[\"top-bar\"])\n",
    "\n",
    "\n",
    "\n",
    "layout = pn.Column(top_bar, processing_panel, sizing_mode='stretch_width')\n",
    "# on click of buttons change the layout\n",
    "\n",
    "\n",
    "def openProcessing(*events):\n",
    "    resetAllButtons()\n",
    "    process_button.button_type = 'primary'\n",
    "    layout[1].loading = True\n",
    "    layout[1] = processing_panel\n",
    "    layout[1].loading = False\n",
    "\n",
    "\n",
    "def openFeatureImportance(*events):\n",
    "    resetAllButtons()\n",
    "    feature_importance_button.button_type = 'primary'\n",
    "    layout[1].loading = True\n",
    "    layout[1] = feature_importance_panel\n",
    "    layout[1].loading = False\n",
    "\n",
    "\n",
    "def openML(*events):\n",
    "    resetAllButtons()\n",
    "    machine_learning_button.button_type = 'primary'\n",
    "    layout[1].loading = True\n",
    "    layout[1] = ml_panel\n",
    "    layout[1].loading = False\n",
    "\n",
    "def openInsights(*events):\n",
    "    resetAllButtons()\n",
    "    insights_button.button_type = 'primary'\n",
    "    layout[1].loading = True\n",
    "    layout[1] = insights_panel\n",
    "    layout[1].loading = False\n",
    "\n",
    "\n",
    "def openData(*events):\n",
    "    resetAllButtons()\n",
    "    data_button.button_type = 'primary'\n",
    "    layout[1].loading = True\n",
    "    layout[1] = data_panel\n",
    "    layout[1].loading = False\n",
    "\n",
    "\n",
    "def openConsole(*events):\n",
    "    resetAllButtons()\n",
    "    console_button.button_type = 'primary'\n",
    "    layout[1].loading = True\n",
    "    layout[1] = console_panel\n",
    "    layout[1].loading = False\n",
    "\n",
    "\n",
    "process_button.on_click(openProcessing)\n",
    "insights_button.on_click(openInsights)\n",
    "machine_learning_button.on_click(openML)\n",
    "data_button.on_click(openData)\n",
    "console_button.on_click(openConsole)\n",
    "feature_importance_button.on_click(openFeatureImportance)\n",
    "\n",
    "layout.servable()\n",
    "# we can serve via cmd using : panel serve test.ipynb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b306ae2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
